{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TP_6-Clasificación_de_imagenes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDSdZpfxJtKd"
      },
      "source": [
        "# 1. Objetivo\n",
        "\n",
        "La idea del proycto es realizar una clasificación de imágenes en tres clases -> Frutas, Vegetales y Paquetes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5PsOz_aFbsY"
      },
      "source": [
        "#### data set reference\n",
        "```\n",
        "  title={A Hierarchical Grocery Store Image Dataset with Visual and Semantic Labels},\n",
        "  author={Klasson, Marcus and Zhang, Cheng and Kjellstr{\\\"o}m, Hedvig},\n",
        "  booktitle={IEEE Winter Conference on Applications of Computer Vision (WACV)},\n",
        "  year={2019}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOpdUtkApTp3"
      },
      "source": [
        "## Un puntapie de inicio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "_JvVJdpidmBl"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from six.moves import urllib\n",
        "import io\n",
        "import shutil\n",
        "\n",
        "from IPython.display import clear_output, Image, display, HTML\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.metrics as sk_metrics\n",
        "import time\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions, ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras import regularizers\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout, Flatten\n",
        "from keras import backend as K"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWcbdolPpGf8"
      },
      "source": [
        "#### Vamos a crear algunas funciones útiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "HvbR62Pph6Sk"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    classes = classes\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "  \n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxI7IjZ759Yg"
      },
      "source": [
        "# 2. Descarga y Armado del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm-GSOl_sKDy",
        "outputId": "38b0844c-6496-4711-d606-0bf8e5d26a84"
      },
      "source": [
        "!git clone https://github.com/marcusklasson/GroceryStoreDataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GroceryStoreDataset'...\n",
            "remote: Enumerating objects: 6556, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 6556 (delta 0), reused 1 (delta 0), pack-reused 6553\u001b[K\n",
            "Receiving objects: 100% (6556/6556), 116.25 MiB | 13.11 MiB/s, done.\n",
            "Resolving deltas: 100% (313/313), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9W6KsnAsslX"
      },
      "source": [
        "## fijamos los paths\n",
        "train_path = './GroceryStoreDataset/dataset/train' \n",
        "validation_path = './GroceryStoreDataset/dataset/val'\n",
        "test_path = './GroceryStoreDataset/dataset/test'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8xg2qo_Fbsg",
        "outputId": "4cc0b227-ac1f-4af2-f44c-818a64d994b8"
      },
      "source": [
        "!ls GroceryStoreDataset/dataset/train/Fruit"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple\t Kiwi\tMango\t   Orange\t  Peach      Plum\t     Satsumas\n",
            "Avocado  Lemon\tMelon\t   Papaya\t  Pear\t     Pomegranate\n",
            "Banana\t Lime\tNectarine  Passion-Fruit  Pineapple  Red-Grapefruit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL0tx8JJ6Jr3"
      },
      "source": [
        "## 2.2 Preprocesamiento inicial de los datos¿\n",
        "Creamos algunos preprocesamientos sin ningun variación ni aumento de los datos. Este es el comienzo :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMwUbPWH4Tyo",
        "outputId": "fd0eba6b-ca8d-4ebd-ca51-cf714f87735d"
      },
      "source": [
        "train_batches  = ImageDataGenerator().flow_from_directory(\n",
        "    train_path, target_size=(224,224), classes = ['Fruit', 'Packages', 'Vegetables'], batch_size = 32)\n",
        "\n",
        "validation_batches  = ImageDataGenerator().flow_from_directory(\n",
        "    validation_path, target_size=(224,224), classes = ['Fruit', 'Packages', 'Vegetables'], batch_size = 8)\n",
        "\n",
        "test_batches  = ImageDataGenerator().flow_from_directory(\n",
        "    test_path, target_size=(224,224), classes = ['Fruit', 'Packages', 'Vegetables'], batch_size = 32)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2640 images belonging to 3 classes.\n",
            "Found 296 images belonging to 3 classes.\n",
            "Found 2485 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6redeyP_8zM",
        "outputId": "5b5eb2b1-a1a1-4312-da93-478c0668e002"
      },
      "source": [
        "#take a look at output of the generators\n",
        "\n",
        "for data_batch, labels_batch in train_batches:\n",
        "    print('data batch shape:', data_batch.shape)\n",
        "    print('labels batch shape:', labels_batch.shape)\n",
        "    break\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data batch shape: (32, 224, 224, 3)\n",
            "labels batch shape: (32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDUbhD1YMhd1"
      },
      "source": [
        "# 3. Crear un Modelo base Convolusional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz-vexo6Mf3X",
        "outputId": "f621a708-4781-4191-ab1f-785137310fde"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(224, 224, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(96, activation='relu'))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 394272)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 96)                37850208  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 291       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37,851,395\n",
            "Trainable params: 37,851,395\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "iaolHAf5NxRS",
        "outputId": "a72a500b-3dc5-4983-f07c-4fcb15413407"
      },
      "source": [
        "train_filenames = train_batches.filenames\n",
        "steps_train = len(train_filenames)/train_batches.batch_size\n",
        "\n",
        "validation_filenames = validation_batches.filenames\n",
        "steps_valid = len(validation_filenames)/validation_batches.batch_size\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "fit_generator1 = model.fit(\n",
        "      train_batches,\n",
        "      steps_per_epoch=steps_train,\n",
        "      epochs=5,\n",
        "      validation_data=validation_batches,\n",
        "      validation_steps=steps_valid)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-83f300455ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model.compile(loss='categorical_crossentropy',\n\u001b[0;32m----> 8\u001b[0;31m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m               metrics=['acc'])\n\u001b[1;32m     10\u001b[0m fit_generator1 = model.fit(\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.optimizers' has no attribute 'RMSprop'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "Y0xtfvl4s-DS",
        "outputId": "4d802ee3-7727-4f23-b320-1f5d92d87392"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = fit_generator1.history['acc']\n",
        "val_acc = fit_generator1.history['val_acc']\n",
        "loss = fit_generator1.history['loss']\n",
        "val_loss = fit_generator1.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc', color = 'r')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss', color = 'r')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f68b5bcff2c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_generator1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_generator1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_generator1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fit_generator1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoSig-jkFbsj"
      },
      "source": [
        "### 3.1.1 Experimentar con el modelo... Prueben hacer un modelo un poco más complejo, con:\n",
        " \n",
        " Capa convolusional con 32 neuronas\n",
        " \n",
        " Capa Pooling\n",
        " \n",
        " Capa Convolusional con 64 neuronas\n",
        " \n",
        " Capa Pooling\n",
        " \n",
        " Capa Convolusional con 128 neuronas\n",
        " \n",
        " Capa Pooling\n",
        " \n",
        " Capa Convolusional con 128 neuronas\n",
        " \n",
        " Capa Pooling\n",
        " \n",
        " Capa de Aplanamiento\n",
        " \n",
        " Capa Densa con 512 neuronas\n",
        " \n",
        " Capa de clasificación con la categorías.\n",
        " \n",
        " ** y obviamente probar con más épocas ** \n",
        " \n",
        " Se recomienda entrenar con gpu (o en colab), aunque puede andar sin, aunque bastante lento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a5BfXwvFbsj"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mmQfoQLYGHp"
      },
      "source": [
        "### 3.2 Hacer Aumento de datos\n",
        "\n",
        "Para el mismo modelo que armamos arriba (es decir, una vez que definan uno, se quedan con ese), hagamos un poco de aumento de cantidad de datos. Es una buena forma de tener más datos y prevenir también el overfitting. \n",
        "\n",
        "Se puede aumentar los datos con los generadores de entrenamiento. Se recomienta usar reescalamiento, recorte, zoom y espejado horizontal.\n",
        "\n",
        "* reescalar los inputs de 0,255 a 0,1\n",
        "* aplicar el rango de recorte (shear_range) para aplicar cortes aleatorios\n",
        "* aplicar rango de zoom (zoom_range) para aplicar zoom aleatorio a las imágenes\n",
        "* poner true el espejado horizontal (horizontal_flip) para obtener imágenes espejo horizontales)\n",
        "\n",
        "Recuerden usar las mismas funciones de activación y optimización, para poder probar el mismo modelo.\n",
        "\n",
        "Siempre recuerden plotear validación contra training para ver si hay overfitting.\n",
        "\n",
        "Recuerden que hay que reescalar el test también, porque el modelo aprendió a utilizar los datos escalados\n",
        "\n",
        "un buen lugar para consultar sobre Image Data Generator (la herramienta para aumentar los datos)\n",
        "https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "6djhkyIVFbsk",
        "outputId": "fbcdbf71-a7e0-45e5-ed17-78b9b65a776b"
      },
      "source": [
        "#### Les dejo algo de código para que vayan empezando\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=###,\n",
        "        width_shift_range=###,\n",
        "        height_shift_range=0.###,\n",
        "        fill_mode=#####,\n",
        "        rescale=####,\n",
        "        shear_range=####,\n",
        "        zoom_range=####,\n",
        "        horizontal_flip=####)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=####)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=50,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=10,\n",
        "        class_mode='categorical')\n",
        "\n",
        "train_filenames = train_generator.filenames\n",
        "steps_train = len(train_filenames)/train_generator.batch_size\n",
        "\n",
        "validation_filenames = validation_generator.filenames\n",
        "steps_valid = len(validation_filenames)/validation_generator.batch_size\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "fit_generator_2 = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_train,\n",
        "        epochs=30,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=steps_valid)\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-c5633ebd01db>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    width_shift_range=###,\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzfs7FPcpLkZ"
      },
      "source": [
        "### 3.3 Más aumentos de imágenes \n",
        "\n",
        "Probemos agregar otros aumentos:\n",
        "\n",
        "* rango de rotación (rotation_range) rota las imagenes.\n",
        "* desplazar las imagenes aleatoriamente con (width_shift) en ancho\n",
        "* desplazar las imagenes aleatoriamente con (height_shift) en ancho\n",
        "* poner fill_mode en nearest para completar la imagen.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQmLOTdKFbsl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM9KW0tW5yJo"
      },
      "source": [
        "### 3.3 Regularización: Añadir capa o capas de dropout para regularizar.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRtFPWolFbsl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nrWwkEPNiJf"
      },
      "source": [
        "# 4. Utilizar una Red Preentrenada y hacer Fine-Tuning!\n",
        "\n",
        "Probar con VGG16, recortando las últimas capas de la red para hacer fine tuning. El que se anime, puede probar ResNet también que es una red con una arquitectura bastante más compleja!\n",
        "\n",
        "Recuerden que tienen que setear cuáles serán las capas a entrenar.\n",
        "Les dejo documentación al respecto! :)\n",
        "\n",
        "https://www.pyimagesearch.com/2019/06/03/fine-tuning-with-keras-and-deep-learning/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjDvRBPOYGqu"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from six.moves import urllib\n",
        "import io\n",
        "import shutil\n",
        "import keras\n",
        "from IPython.display import clear_output, Image, display, HTML\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.metrics as sk_metrics\n",
        "import time\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras import regularizers\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout, Flatten\n",
        "from keras import backend as K"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPM8OTu8uGxp"
      },
      "source": [
        "#### Recuerden que aquí, cuando ya estén medio estables con los resultados, pueden empezar a jugar con los optimizadores y también realizar el aumento de imágenes para el modelo con vgg o resnet :)\n",
        "#### SUERTE Y CUALQUIER COSA  ME PREGUNTAN!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI6jbL97Fbsm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}